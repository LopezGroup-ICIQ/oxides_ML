{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - Replace these paths with your data locations\n",
    "# Or set environment variables: HYPERPARAMETER_OPT_DIR\n",
    "# ============================================================================\n",
    "\n",
    "root_dir = os.environ.get(\n",
    "    \"HYPERPARAMETER_OPT_DIR\",\n",
    "    \"./models/hyperparameter_optimization/initial_test/initial\"\n",
    ")\n",
    "\n",
    "print(f\"Hyperparameter optimization directory: {root_dir}\")\n",
    "\n",
    "datasets = [\"Set1\", \"Set2\", \"Set3\"]  # Add more dataset names as needed\n",
    "QoI = \"architecture_dim\" \n",
    "independent_variable = QoI\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    parent_dir = os.path.join(root_dir, dataset, QoI)\n",
    "    summary_data = []\n",
    "    \n",
    "    for model_folder in os.listdir(parent_dir):\n",
    "        model_path = os.path.join(parent_dir, model_folder)\n",
    "        \n",
    "        if os.path.isdir(model_path):\n",
    "            summary_entry = {'Dataset': dataset, 'Model': model_folder}\n",
    "\n",
    "            # Load test set\n",
    "            test_set_path = os.path.join(model_path, \"test_set.csv\")\n",
    "            if os.path.exists(test_set_path):\n",
    "                df_test = pd.read_csv(test_set_path)\n",
    "                summary_entry['MAE'] = df_test['Abs_error_eV'].mean()\n",
    "\n",
    "            # Load hyperparameters from .txt file\n",
    "            hyperparam_path = os.path.join(model_path, \"input.txt\")\n",
    "            if os.path.exists(hyperparam_path):\n",
    "                with open(hyperparam_path, \"r\") as file:\n",
    "                    hyperparams = ast.literal_eval(file.read())\n",
    "\n",
    "                def flatten_dict(d, parent_key='', sep='_'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.loc[df_combined['MAE'].idxmin(), [\"Dataset\", \"Model\", independent_variable, \"MAE\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.environ.get(\n",
    "    \"HYPERPARAMETER_OPT_DIR_AUGMENT\",\n",
    "    \"./models/hyperparameter_optimization/initial_test/augment\"\n",
    ")\n",
    "\n",
    "print(f\"Hyperparameter optimization (augmented) directory: {root_dir}\")\n",
    "\n",
    "datasets = [\"Set1\",\"Set2\",\"Set3\", \"Set15\"] \n",
    "\n",
    "all_data = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    parent_dir = os.path.join(root_dir, dataset, QoI)\n",
    "    summary_data = []\n",
    "    \n",
    "    for model_folder in os.listdir(parent_dir):\n",
    "        model_path = os.path.join(parent_dir, model_folder)\n",
    "        \n",
    "        if os.path.isdir(model_path):\n",
    "            summary_entry = {'Dataset': dataset, 'Model': model_folder}\n",
    "\n",
    "            # Load test set\n",
    "            test_set_path = os.path.join(model_path, \"test_set.csv\")\n",
    "            if os.path.exists(test_set_path):\n",
    "                df_test = pd.read_csv(test_set_path)\n",
    "                summary_entry['MAE'] = df_test['Abs_error_eV'].mean()\n",
    "\n",
    "            # Load hyperparameters from .txt file\n",
    "            hyperparam_path = os.path.join(model_path, \"input.txt\")\n",
    "            if os.path.exists(hyperparam_path):\n",
    "                with open(hyperparam_path, \"r\") as file:\n",
    "                    hyperparams = ast.literal_eval(file.read())\n",
    "\n",
    "                def flatten_dict(d, parent_key='', sep='_'):\n",
    "                    items = []\n",
    "                    for k, v in d.items():\n",
    "                        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "                        if isinstance(v, dict):\n",
    "                            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "                        else:\n",
    "                            items.append((new_key, v))\n",
    "                    return dict(items)\n",
    "\n",
    "                flat_hyperparams = flatten_dict(hyperparams)\n",
    "                summary_entry.update(flat_hyperparams)\n",
    "\n",
    "            summary_data.append(summary_entry)\n",
    "    \n",
    "    df_summary_augment = pd.DataFrame(summary_data)\n",
    "    all_data.append(df_summary_augment)\n",
    "\n",
    "# Combine all datasets into a single DataFrame\n",
    "df_combined_augment = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Sorting\n",
    "df_combined_augment = df_combined_augment.sort_values([\"Dataset\", independent_variable], ascending=True).reset_index()\n",
    "\n",
    "# Compute the average MAE across the datasets\n",
    "df_avg_augment = df_combined_augment.groupby([independent_variable], as_index=False)['MAE'].mean()\n",
    "df_avg_augment['Model'] = 'Average'\n",
    "\n",
    "# Plot MAE across datasets\n",
    "\n",
    "# Use a consistent palette\n",
    "palette = sns.color_palette('hsv', n_colors=len(datasets))\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "# First subplot\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(data=df_combined_augment, x='Model', y='MAE', hue='Dataset', palette=palette, edgecolor='black', legend=False, zorder=10)\n",
    "plt.title('Mean Absolute Error (MAE) Across Models and Datasets')\n",
    "plt.ylabel('Mean Absolute Error (MAE) [eV]')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "# Second subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "for i, dataset in enumerate(datasets):\n",
    "    df_subset_augment = df_combined_augment[df_combined_augment['Dataset'] == dataset].sort_values(by=independent_variable)\n",
    "    \n",
    "    # Line connecting points within the dataset\n",
    "    sns.lineplot(data=df_subset_augment, x=independent_variable, y='MAE', label=f\"{dataset} (line)\", color=palette[i], linewidth=1.5, zorder=5)\n",
    "    \n",
    "    # Scatter plot without custom label (avoid conflict with style)\n",
    "    sns.scatterplot(data=df_subset_augment, x=independent_variable, y='MAE', style='Model', color=palette[i], s=100, edgecolor='black', zorder=10)\n",
    "\n",
    "# Plot average line and scatter\n",
    "df_avg_sorted_augment = df_avg_augment.sort_values(by=independent_variable)\n",
    "sns.lineplot(data=df_avg_sorted_augment, x=independent_variable, y='MAE', color='black', linewidth=2.5, label='Average', zorder=12)\n",
    "\n",
    "sns.scatterplot(data=df_avg_sorted_augment, x=independent_variable, y='MAE', color='black', marker='X', s=200, label='_nolegend_', zorder=15\n",
    ")\n",
    "\n",
    "plt.xlabel(independent_variable)\n",
    "plt.ylabel('Mean Absolute Error (MAE) [eV]')\n",
    "plt.title(f'MAE vs. {independent_variable} Across Datasets')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Legend', bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "plt.subplots_adjust(wspace=0.15)\n",
    "\n",
    "if independent_variable == \"train_minlr\":\n",
    "    plt.xscale('log')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_augment.loc[df_combined_augment['MAE'].idxmin(), [\"Dataset\", \"Model\", independent_variable, \"MAE\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare augment vs initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a consistent color palette\n",
    "palette = sns.color_palette('hsv', n_colors=len(datasets))\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 6), sharey=True)\n",
    "\n",
    "# First subplot\n",
    "for i, dataset in enumerate(datasets):\n",
    "    df_subset = df_combined[df_combined['Dataset'] == dataset].sort_values(by=independent_variable)\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=df_subset, x=independent_variable, y='MAE',\n",
    "        label=f\"{dataset} (line)\", color=palette[i], linewidth=1.5,\n",
    "        zorder=5, ax=ax[0]\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=df_subset, x=independent_variable, y='MAE',\n",
    "        style='Model', color=palette[i], s=100, edgecolor='black',\n",
    "        zorder=10, ax=ax[0]\n",
    "    )\n",
    "\n",
    "# Average line and scatter\n",
    "df_avg_sorted = df_avg.sort_values(by=independent_variable)\n",
    "sns.lineplot(data=df_avg_sorted, x=independent_variable, y='MAE',\n",
    "             color='black', linewidth=2.5, label='Average', zorder=12, ax=ax[0])\n",
    "sns.scatterplot(data=df_avg_sorted, x=independent_variable, y='MAE',\n",
    "                color='black', marker='X', s=200, label='_nolegend_', zorder=15, ax=ax[0])\n",
    "\n",
    "# Aesthetics for first plot\n",
    "ax[0].set_xlabel(independent_variable)\n",
    "ax[0].set_ylabel('Mean Absolute Error (MAE) [eV]')\n",
    "ax[0].set_title(f'MAE vs. {independent_variable} Across Datasets (initial dataset)')\n",
    "ax[0].grid(True)\n",
    "# ax[0].set_xscale('log' if independent_variable == \"train_minlr\" else 'linear')\n",
    "\n",
    "# Hide legend on first plot\n",
    "ax[0].get_legend().remove()\n",
    "\n",
    "\n",
    "# Second subplot\n",
    "for i, dataset in enumerate(datasets):\n",
    "    df_subset_augment = df_combined_augment[df_combined_augment['Dataset'] == dataset].sort_values(by=independent_variable)\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=df_subset_augment, x=independent_variable, y='MAE',\n",
    "        label=f\"{dataset} (line)\", color=palette[i], linewidth=1.5,\n",
    "        zorder=5, ax=ax[1]\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=df_subset_augment, x=independent_variable, y='MAE',\n",
    "        style='Model', color=palette[i], s=100, edgecolor='black',\n",
    "        zorder=10, ax=ax[1]\n",
    "    )\n",
    "\n",
    "# Average line and scatter\n",
    "df_avg_sorted_augment = df_avg_augment.sort_values(by=independent_variable)\n",
    "sns.lineplot(data=df_avg_sorted_augment, x=independent_variable, y='MAE',\n",
    "             color='black', linewidth=2.5, label='Average', zorder=12, ax=ax[1])\n",
    "sns.scatterplot(data=df_avg_sorted_augment, x=independent_variable, y='MAE',\n",
    "                color='black', marker='X', s=200, label='_nolegend_', zorder=15, ax=ax[1])\n",
    "\n",
    "# Aesthetics for second plot\n",
    "ax[1].set_xlabel(independent_variable)\n",
    "ax[1].set_ylabel('Mean Absolute Error (MAE) [eV]')\n",
    "ax[1].set_title(f'MAE vs. {independent_variable} Across Datasets (augmented dataset)')\n",
    "# ax[1].set_xscale('log' if independent_variable == \"train_minlr\" else 'linear')\n",
    "ax[1].grid(True)\n",
    "\n",
    "# Add legend only to second plot\n",
    "ax[1].legend(title='Molecule Group', bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "\n",
    "# Layout adjustments\n",
    "plt.subplots_adjust(wspace=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - Replace this path with your data location\n",
    "# Or set environment variable: HYPERPARAMETER_OPT_BASE_DIR\n",
    "# ============================================================================\n",
    "\n",
    "hyperparameter_opt_base_dir = os.environ.get(\n",
    "    \"HYPERPARAMETER_OPT_BASE_DIR\",\n",
    "    \"./models/hyperparameter_optimization\"\n",
    ")\n",
    "\n",
    "print(f\"Base hyperparameter optimization directory: {hyperparameter_opt_base_dir}\")\n",
    "\n",
    "def plot_mae_barplot_with_whiskers(QoI: str, database: str):\n",
    "    \"\"\"\n",
    "    Plot barplots of MAE with min/max whiskers for a given QoI or baseline across datasets.\n",
    "\n",
    "    Parameters:\n",
    "        QoI (str): Name of the hyperparameter or 'none' for baseline.\n",
    "        database (str): Name of the subdirectory under the root path.\n",
    "    \"\"\"\n",
    "    root_dir = os.path.join(hyperparameter_opt_base_dir, database)\n",
    "    independent_variable = QoI.replace(\"-\", \"_\") if QoI != \"none\" else \"Model\"\n",
    "\n",
    "    # --- Determine datasets ---\n",
    "    datasets = sorted({\n",
    "        d\n",
    "        for run_folder in os.listdir(root_dir)\n",
    "        if os.path.isdir(os.path.join(root_dir, run_folder))\n",
    "        for d in os.listdir(os.path.join(root_dir, run_folder))\n",
    "        if os.path.isdir(os.path.join(root_dir, run_folder, d))\n",
    "    })\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    def flatten_dict(d, parent_key='', sep='_'):\n",
    "        items = []\n",
    "        for k, v in d.items():\n",
    "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "            if isinstance(v, dict):\n",
    "                items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "            else:\n",
    "                items.append((new_key, v))\n",
    "        return dict(items)\n",
    "\n",
    "    # --- Traverse directory and collect data ---\n",
    "    for run_folder in os.listdir(root_dir):\n",
    "        run_path = os.path.join(root_dir, run_folder)\n",
    "        if not os.path.isdir(run_path):\n",
    "            continue\n",
    "\n",
    "        for dataset in datasets:\n",
    "            dataset_path = os.path.join(run_path, dataset)\n",
    "            if not os.path.isdir(dataset_path):\n",
    "                continue\n",
    "\n",
    "            model_folders = [\"base\"] if QoI == \"none\" else [QoI]\n",
    "            for model_folder in model_folders:\n",
    "                model_path = os.path.join(dataset_path, model_folder)\n",
    "                if not os.path.isdir(model_path):\n",
    "                    continue\n",
    "\n",
    "                param_folders = [\"\"] if QoI == \"none\" else os.listdir(model_path)\n",
    "\n",
    "                for param_val in param_folders:\n",
    "                    full_path = os.path.join(model_path, param_val) if QoI != \"none\" else model_path\n",
    "                    if not os.path.isdir(full_path):\n",
    "                        continue\n",
    "\n",
    "                    input_path = os.path.join(full_path, \"input_config\")\n",
    "                    entry = {\n",
    "                        \"Dataset\": dataset,\n",
    "                        \"Run\": run_folder,\n",
    "                        \"Model\": \"base\" if QoI == \"none\" else f\"{QoI}_{param_val}\"\n",
    "                    }\n",
    "\n",
    "                    test_csv = os.path.join(input_path, \"test_set.csv\")\n",
    "                    if os.path.exists(test_csv):\n",
    "                        df = pd.read_csv(test_csv)\n",
    "                        entry[\"MAE\"] = df[\"Abs_error_eV\"].mean()\n",
    "\n",
    "                    param_txt = os.path.join(input_path, \"input.txt\")\n",
    "                    if os.path.exists(param_txt):\n",
    "                        with open(param_txt, \"r\") as f:\n",
    "                            hyperparams = ast.literal_eval(f.read())\n",
    "                        flat_params = flatten_dict(hyperparams)\n",
    "                        entry.update(flat_params)\n",
    "\n",
    "                    all_data.append(entry)\n",
    "\n",
    "    # --- Data aggregation ---\n",
    "    df_combined = pd.DataFrame(all_data)\n",
    "    df_combined = df_combined.sort_values([\"Dataset\", independent_variable]).reset_index(drop=True)\n",
    "\n",
    "    df_avg_runs = df_combined.groupby([\"Dataset\", independent_variable]).agg(MAE=(\"MAE\", \"mean\")).reset_index()\n",
    "    df_whiskers = df_combined.groupby([\"Dataset\", independent_variable]).agg(\n",
    "        MAE_min=(\"MAE\", \"min\"),\n",
    "        MAE_max=(\"MAE\", \"max\")\n",
    "    ).reset_index()\n",
    "\n",
    "    df_plot = pd.merge(df_avg_runs, df_whiskers, on=[\"Dataset\", independent_variable])\n",
    "\n",
    "    # --- Plotting ---\n",
    "    sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "    palette = sns.color_palette(\"Set2\", n_colors=len(datasets))\n",
    "\n",
    "    x_data = \"Dataset\" if QoI == \"none\" else independent_variable\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    sns.barplot(data=df_plot, x=x_data, y='MAE', hue='Dataset', palette=palette, errorbar=None)\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        subset = df_plot[df_plot[\"Dataset\"] == dataset]\n",
    "        for _, row in subset.iterrows():\n",
    "            plt.errorbar(\n",
    "                x=row[x_data], \n",
    "                y=row['MAE'], \n",
    "                yerr=[[row['MAE'] - row['MAE_min']], [row['MAE_max'] - row['MAE']]],  # asymmetric error\n",
    "                fmt='none',\n",
    "                ecolor='black',\n",
    "                elinewidth=2.5,\n",
    "                capsize=8,\n",
    "                capthick=2\n",
    "            )\n",
    "\n",
    "    plt.xlabel(QoI if QoI != \"none\" else \"Model\")\n",
    "    plt.ylabel(\"Mean Absolute Error (MAE) [eV]\")\n",
    "    plt.title(f\"MAE vs. {QoI if QoI != 'none' else 'Baseline Model'} Across Datasets\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    if QoI != \"none\":\n",
    "        plt.legend(title=\"Legend\", bbox_to_anchor=(1.01, 1), loc=\"upper left\")\n",
    "\n",
    "    if \"lr\" in QoI:\n",
    "        plt.xscale(\"log\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mae_barplot_with_whiskers(\"none\", \"CN_database_1\")\n",
    "plot_mae_barplot_with_whiskers(\"none\", \"BS_database_1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oxides_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

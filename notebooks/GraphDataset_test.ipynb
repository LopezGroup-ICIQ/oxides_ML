{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from typing import Union, Optional\n",
    "import pubchempy as pcp\n",
    "from collections import Counter\n",
    "import re\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch import load, save, tensor\n",
    "import torch \n",
    "\n",
    "from ase.io import read\n",
    "from ase import Atoms\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Add src folder to the sys.path\n",
    "src_path = \"../src\"\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "from oxides_ml.constants import ADSORBATE_ELEMS, METALS, OHE_ELEMENTS\n",
    "from oxides_ml.graph_filters import fragment_filter\n",
    "from oxides_ml.graph_care import atoms_to_pyg\n",
    "from oxides_ml.node_featurizers import get_gcn, get_cn\n",
    "from oxides_ml.graph_tools import graph_plotter\n",
    "\n",
    "def pyg_dataset_id(vasp_directory: str, \n",
    "                   graph_params: dict,\n",
    "                   initial_state: bool,\n",
    "                   augment: bool) -> str:\n",
    "    \"\"\"\n",
    "    Return dataset identifier based on the graph conversion settings.\n",
    "    \n",
    "    Args:\n",
    "        vasp_directory (str): Path to the directory containing VASP simulation files.\n",
    "        graph_params (dict): Dictionary containing the information for the graph generation \n",
    "                             in the format:\n",
    "                            {\"structure\": {\"tolerance\": float, \"scaling_factor\": float, \"surface_order\": int},\n",
    "                             \"features\": {\"encoder\": OneHotEncoder, \"adsorbate\": bool, \"ring\": bool, \"aromatic\": bool, \"radical\": bool, \"valence\": bool, \"facet\": bool}}\n",
    "    Returns:\n",
    "        dataset_id (str): PyG dataset identifier.\n",
    "    \"\"\"\n",
    "    # Extract directory name as ID\n",
    "    id = os.path.basename(os.path.abspath(vasp_directory))\n",
    "\n",
    "    # Extract graph structure conversion params\n",
    "    structure_params = graph_params[\"structure\"]\n",
    "    tolerance = str(structure_params[\"tolerance\"]).replace(\".\", \"\")\n",
    "    scaling_factor = str(structure_params[\"scaling_factor\"]).replace(\".\", \"\")\n",
    "    surface_order_nn = str(structure_params[\"surface_order\"])\n",
    "    \n",
    "    # Extract node features parameters\n",
    "    features_params = graph_params[\"features\"]\n",
    "    adsorbate = str(features_params[\"adsorbate\"])\n",
    "    radical = str(features_params[\"radical\"])\n",
    "    valence = str(features_params[\"valence\"])\n",
    "    cn = str(features_params[\"cn\"])\n",
    "    mag = str(features_params[\"magnetization\"])\n",
    "    ads_height = str(features_params[\"ads_height\"])\n",
    "    target = graph_params[\"target\"]\n",
    "    state_tag = \"initial\" if initial_state == True else \"relaxed\"\n",
    "    augment_tag = \"True\" if augment == True else \"False\"\n",
    "    \n",
    "    # Generate dataset ID\n",
    "    dataset_id = \"{}_{}_{}_{}_{}_{}_{}_{}_{}_{}_{}_{}_{}\".format(\n",
    "        id, target, tolerance, scaling_factor, surface_order_nn, \n",
    "        adsorbate, radical, valence, cn, mag, ads_height, state_tag, augment_tag\n",
    "    )\n",
    "    \n",
    "    return dataset_id\n",
    "\n",
    "# Function to get the parent directory\n",
    "def get_parent_dir(path, levels=1):\n",
    "    for _ in range(levels):\n",
    "        path = os.path.dirname(path)\n",
    "    return path\n",
    "\n",
    "def extract_ispin(incar_path: str):\n",
    "    \"\"\"\n",
    "    Extract the ISPIN value from the VASP INCAR file.\n",
    "\n",
    "    Args:\n",
    "        incar_path (str): Path to the INCAR file.\n",
    "\n",
    "    Returns:\n",
    "        int or None: Extracted ISPIN value (1 or 2), or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(incar_path, \"r\") as file:\n",
    "            for line in file:\n",
    "                if \"ISPIN\" in line:\n",
    "                    parts = line.split(\"=\")\n",
    "                    if len(parts) > 1:\n",
    "                        return int(parts[1].strip().split()[0])  # Extract first number\n",
    "    except FileNotFoundError:\n",
    "        print(f\"INCAR file not found: {incar_path}\")\n",
    "    except ValueError:\n",
    "        print(\"Error parsing ISPIN value in INCAR.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading INCAR: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_energy(outcar_path: str):\n",
    "    \"\"\"\n",
    "    Extract total energy from VASP OUTCAR file using grep.\n",
    "\n",
    "    Args:\n",
    "        outcar_path (str): Path to the OUTCAR file.\n",
    "\n",
    "    Returns:\n",
    "        float or None: Extracted total energy in eV, or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run grep to find lines with \"energy(sigma->0)\"\n",
    "        result = subprocess.run(\n",
    "            [\"grep\", \"energy(sigma->0)\", outcar_path],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "\n",
    "        # Extract the last value from the line\n",
    "        last_line = result.stdout.strip().split(\"\\n\")[-1]  # Get the last occurrence\n",
    "        energy = float(last_line.split()[-1])  # Extract energy value\n",
    "        return energy\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"OUTCAR file not found: {outcar_path}\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"Pattern 'energy(sigma->0)' not found in {outcar_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading OUTCAR: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Extract Metadata\n",
    "def extract_metadata(path: str):\n",
    "    \"\"\"\n",
    "    Extract metadata based on the file path structure.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path of the CONTCAR/POSCAR file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Metadata with 'material', 'adsorbate_group', 'adsorbate_name', \"total_energy\" (DFT-energy), \"slab_energy\", \"adsorbate_energy\", and \"adsorption_energy\".\n",
    "    \"\"\"\n",
    "    parts = path.split(os.sep)\n",
    "\n",
    "    metadata = {\n",
    "        \"material\": None,\n",
    "        \"adsorbate_group\": None,\n",
    "        \"adsorbate_name\": None,\n",
    "        \"total_energy\": None,\n",
    "        \"adsorbate_energy\": None,\n",
    "        \"slab_energy\": None,\n",
    "        \"adsorption_energy\": None,\n",
    "        \"facet\": None,\n",
    "        \"type\": None,\n",
    "        \"spin_polarization\": None,\n",
    "        \"state_of_origin\": \"initial\" if \"POSCAR\" in path or \"poscar_1\" in path else \"relaxed\"\n",
    "    }\n",
    "\n",
    "    if \"gas_phase\" in parts:\n",
    "        metadata[\"material\"] = \"None\"\n",
    "        metadata[\"adsorbate_group\"] = parts[-3]\n",
    "        metadata[\"adsorbate_name\"] = parts[-2]\n",
    "\n",
    "        metadata[\"total_energy\"] = extract_energy(os.path.join(os.path.dirname(path), \"OUTCAR\"))\n",
    "        metadata[\"adsorbate_energy\"] = extract_energy(os.path.join(os.path.dirname(path), \"OUTCAR\"))\n",
    "\n",
    "        metadata[\"facet\"] = \"None\"\n",
    "        metadata[\"type\"] = \"gas\"\n",
    "        metadata[\"spin_polarization\"] = extract_ispin(os.path.join(os.path.dirname(path), \"INCAR\"))\n",
    "\n",
    "    elif \"slab\" in parts:\n",
    "        metadata[\"material\"] = parts[-2]\n",
    "        metadata[\"adsorbate_group\"] = \"None\"\n",
    "        metadata[\"adsorbate_name\"] = \"None\"\n",
    "\n",
    "        metadata[\"total_energy\"] = extract_energy(os.path.join(os.path.dirname(path), \"OUTCAR\"))\n",
    "        metadata[\"slab_energy\"] = extract_energy(os.path.join(os.path.dirname(path), \"OUTCAR\"))\n",
    "\n",
    "        metadata[\"facet\"] = \"110\"\n",
    "        metadata[\"type\"] = \"slab\"\n",
    "        metadata[\"spin_polarization\"] = extract_ispin(os.path.join(os.path.dirname(path), \"INCAR\"))\n",
    "\n",
    "    elif (\"oxide_adsorbates\" in parts) or (\"metal_adsorbates\" in parts):\n",
    "        metadata[\"material\"] = parts[-6]\n",
    "        metadata[\"adsorbate_group\"] = parts[-5]\n",
    "        metadata[\"adsorbate_name\"] = parts[-4]\n",
    "\n",
    "        metadata[\"total_energy\"] = extract_energy(os.path.join(os.path.dirname(path), \"OUTCAR\"))\n",
    "        metadata[\"slab_energy\"] = extract_energy(os.path.join(get_parent_dir(path, 7), \"slab\", metadata[\"material\"], \"OUTCAR\"))\n",
    "        metadata[\"adsorbate_energy\"] = extract_energy(os.path.join(get_parent_dir(path, 7), \"gas_phase\", metadata[\"adsorbate_group\"], metadata[\"adsorbate_name\"], \"OUTCAR\"))\n",
    "        metadata[\"adsorption_energy\"] = metadata[\"total_energy\"] - metadata[\"slab_energy\"] - metadata[\"adsorbate_energy\"]\n",
    "\n",
    "        metadata[\"facet\"] = \"110\"\n",
    "        metadata[\"type\"] = \"adsorbate\"\n",
    "        metadata[\"spin_polarization\"] = extract_ispin(os.path.join(os.path.dirname(path), \"INCAR\"))\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Determine adsorption indices\n",
    "\n",
    "CACHE_FILE = \"adsorbate_indices_cache.json\"\n",
    "\n",
    "# Load or initialize the cache\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"r\") as f:\n",
    "        index_cache = json.load(f)\n",
    "else:\n",
    "    index_cache = {}\n",
    "\n",
    "def get_pubchem_formula(molecule_name):\n",
    "    compounds = pcp.get_compounds(molecule_name, 'name')\n",
    "    if compounds:\n",
    "        pubchem_formula = compounds[0].molecular_formula\n",
    "        return parse_pubchem_formula(pubchem_formula)\n",
    "    return None\n",
    "\n",
    "def parse_pubchem_formula(formula):\n",
    "    pattern = r'([A-Z][a-z]*)(\\d*)'\n",
    "    parsed = re.findall(pattern, formula)\n",
    "    atom_counts = {element: int(count) if count else 1 for element, count in parsed}\n",
    "    return Counter(atom_counts)\n",
    "\n",
    "def get_adsorbate_indices_from_vasp(filepath, total_adsorbate_atoms):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # POSCAR format: atomic symbols on line 5, atom counts on line 6\n",
    "    element_symbols = lines[5].split()\n",
    "    atom_counts = list(map(int, lines[6].split()))\n",
    "    \n",
    "    total_atoms = sum(atom_counts)\n",
    "    adsorbate_start_index = total_atoms - total_adsorbate_atoms\n",
    "    adsorbate_indices = list(range(adsorbate_start_index, total_atoms))  # 0-based indexing\n",
    "\n",
    "    return adsorbate_indices\n",
    "\n",
    "def extract_atom_indices(path: str, offline: bool = False) -> list[int]:\n",
    "    \"\"\"\n",
    "    Extract adsorbate atom indices, with caching based on molecule name and context.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the POSCAR/CONTCAR file.\n",
    "        offline (bool): If True, do not attempt HTTP (PubChem) requests.\n",
    "\n",
    "    Returns:\n",
    "        list[int]: List of adsorbate atom indices.\n",
    "    \"\"\"\n",
    "    parts = path.split(os.sep)\n",
    "\n",
    "    if (\"oxide_adsorbates\" in parts) or (\"metal_adsorbates\" in parts):\n",
    "        surface = parts[-6]\n",
    "        molecule_name = parts[-4]\n",
    "        context = \"surface_adsorbates\"\n",
    "    elif \"gas_phase\" in parts:\n",
    "        surface = \"gas\"\n",
    "        molecule_name = parts[-2]\n",
    "        context = \"gas_phase\"\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "    cache_key = f\"{surface}__{molecule_name}__{context}\"\n",
    "\n",
    "    # Use cache if available\n",
    "    if cache_key in index_cache:\n",
    "        return index_cache[cache_key]\n",
    "    \n",
    "    # If offline, raise an error if not found in cache\n",
    "    if offline:\n",
    "        raise RuntimeError(f\"Adsorbate indices for {cache_key} not in cache and offline=True\")\n",
    "\n",
    "    # Otherwise, compute and cache\n",
    "    parsed_formula = get_pubchem_formula(molecule_name)\n",
    "    if parsed_formula:\n",
    "        total_atoms = sum(parsed_formula.values())\n",
    "        atom_indices = get_adsorbate_indices_from_vasp(path, total_atoms)\n",
    "    else:\n",
    "        atom_indices = []\n",
    "\n",
    "    index_cache[cache_key] = atom_indices\n",
    "    with open(CACHE_FILE, \"w\") as f:\n",
    "        json.dump(index_cache, f, indent=2)\n",
    "\n",
    "    return atom_indices\n",
    "\n",
    "\n",
    "def get_surface_indices_from_graph(graph, cart_coords, METALS = METALS):\n",
    "    \"\"\"\n",
    "    Identifies the surface metal atoms from the graph representation.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: The graph object containing node information.\n",
    "    - METALS: List of metal elements.\n",
    "    - cart_coords: Cartesian coordinates of all atoms.\n",
    "\n",
    "    Returns:\n",
    "    - List of surface indices (indices of metal atoms on the surface).\n",
    "    \"\"\"\n",
    "    surface_indices = []\n",
    "\n",
    "    # Loop through all nodes in the graph\n",
    "    for node_idx, element in enumerate(graph.elem):\n",
    "        if element in METALS:\n",
    "            atom_idx = graph.idx[node_idx]  # Get atom index corresponding to this node\n",
    "            z_coord = cart_coords[atom_idx][2]  # Get z-coordinate of the atom\n",
    "\n",
    "            # Check if this metal atom is part of the surface\n",
    "            # Instead of just comparing to the maximum z-coordinate, check for top layer atoms\n",
    "            max_z =  max(\n",
    "    cart_coords[graph.idx[i]][2]\n",
    "    for i in range(len(graph.elem))\n",
    "    if graph.elem[i] in METALS\n",
    ")\n",
    "\n",
    "            # If the z-coordinate is within a small margin of the maximum z-coordinate, consider it a surface atom\n",
    "            if z_coord >= max_z:\n",
    "                surface_indices.append(atom_idx)\n",
    "            \n",
    "    return surface_indices\n",
    "\n",
    "def get_adsorption_heights_plane_fit(path, graph):\n",
    "    \"\"\"\n",
    "    Computes adsorption heights using the best-fit plane through surface metal atoms.\n",
    "\n",
    "    Supports both CONTCAR and POSCAR files, and handles both Direct and Cartesian coordinates automatically (via ASE).\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): Path to a directory containing a POSCAR/CONTCAR file.\n",
    "    - graph: Graph object that includes adsorbate_indices and structural information.\n",
    "\n",
    "    Returns:\n",
    "    - Updated graph with adsorption heights (in Å).\n",
    "    \"\"\"\n",
    "    \n",
    "    adsorbate_indices = graph.adsorbate_indices\n",
    "\n",
    "    # Default to 0 in case no height is computed\n",
    "    graph.ads_height = 0\n",
    "\n",
    "    # Skip adsorption height calculation for gas-phase molecules or clean slabs\n",
    "    if (graph.type == \"gas\") or (graph.type == \"slab\"):\n",
    "        # Add a zero-filled adsorption height feature for consistency\n",
    "        ads_tensor = torch.zeros((graph.x.shape[0], 1))\n",
    "        graph.x = torch.cat((graph.x, ads_tensor), dim=1)\n",
    "        graph.node_feats.append(\"ads_height\")\n",
    "        return graph\n",
    "\n",
    "    # Load structure directly from provided path\n",
    "    structure = read(path)\n",
    "    cart_coords = structure.get_positions()  # ASE gives Cartesian coordinates in Å\n",
    "\n",
    "    surface_indices = get_surface_indices_from_graph(graph, cart_coords)\n",
    "    surf_coords = cart_coords[surface_indices]\n",
    "\n",
    "    # Fit a best-fit plane through surface atom positions using Singular Value Decomposition (SVD)\n",
    "    centroid = np.mean(surf_coords, axis=0)\n",
    "    shifted = surf_coords - centroid\n",
    "    _, _, vh = np.linalg.svd(shifted)\n",
    "    normal = vh[-1]\n",
    "    normal = normal / np.linalg.norm(normal)\n",
    "    if normal[2] < 0:\n",
    "        normal = -normal\n",
    "\n",
    "    # Compute distance from each adsorbate atom to the plane\n",
    "    height_dict = {}\n",
    "    for i in adsorbate_indices:\n",
    "        point = cart_coords[i]\n",
    "        vec = point - centroid\n",
    "        height = np.dot(vec, normal)                # Project vector onto plane normal\n",
    "        height_dict[i] = height\n",
    "\n",
    "    # Save the minimum adsorption height to the graph\n",
    "    graph.ads_height = min(height_dict.values()) if height_dict else 0\n",
    "\n",
    "    # Create adsorption height tensor for nodes (default to 0)\n",
    "    ads_tensor = torch.zeros((graph.x.shape[0], 1))\n",
    "\n",
    "    # Loop through nodes and set adsorption height if available\n",
    "    for node_idx, ase_idx in enumerate(graph.idx):\n",
    "        # Check if this atom has a height assigned (i.e., it's an adsorbate)\n",
    "        if ase_idx in height_dict:\n",
    "            ads_tensor[node_idx] = height_dict[ase_idx]\n",
    "        else:\n",
    "            ads_tensor[node_idx] = 0.0  # slab/gas atoms get 0\n",
    "\n",
    "    # Append adsorption height as a new node feature\n",
    "    graph.x = torch.cat((graph.x, ads_tensor), dim=1)\n",
    "    graph.node_feats.append(\"ads_height\")\n",
    "    return graph\n",
    "\n",
    "\n",
    "class OxidesGraphDataset(InMemoryDataset):\n",
    "\n",
    "    def __init__(self,\n",
    "             vasp_directory: str,  # Change input parameter\n",
    "             graph_dataset_dir: str,\n",
    "             graph_params: dict[str, Union[dict[str, bool | float], str]],  \n",
    "             ncores: int=os.cpu_count(), \n",
    "             initial_state: bool=False,\n",
    "             augment: bool=False,\n",
    "             force_reload: bool=False):\n",
    "\n",
    "        self.force_reload = force_reload     \n",
    "        self.initial_state = initial_state\n",
    "        self.augment = augment\n",
    "        \n",
    "        self.dataset_id = pyg_dataset_id(vasp_directory, graph_params, initial_state, augment)\n",
    "        self.vasp_directory = os.path.abspath(vasp_directory)\n",
    "        self.root = self.vasp_directory\n",
    "\n",
    "        self.graph_params = graph_params\n",
    "        self.graph_structure_params = graph_params[\"structure\"]\n",
    "        self.node_feats_params = graph_params[\"features\"]\n",
    "        self.target = graph_params[\"target\"]\n",
    "\n",
    "        self.output_path = os.path.join(os.path.abspath(graph_dataset_dir), self.dataset_id)\n",
    "\n",
    "        self.ncores = ncores\n",
    "        ADSORBATE_ELEMENTS = [\"C\", \"H\", \"N\", \"S\"]\n",
    "        self.adsorbate_elems = ADSORBATE_ELEMS\n",
    "        self.elements_list = ADSORBATE_ELEMS + METALS\n",
    "        self.ohe_elements = OHE_ELEMENTS\n",
    "\n",
    "        self.node_feature_list = list(self.ohe_elements.categories_[0])\n",
    "        self.node_dim = len(self.node_feature_list)\n",
    "        for key, value in graph_params[\"features\"].items():\n",
    "            if value:\n",
    "                self.node_dim += 1\n",
    "                self.node_feature_list.append(key.upper())\n",
    "\n",
    "        # **Delete existing dataset if force_reload is enabled**\n",
    "        if self.force_reload and os.path.exists(self.output_path):\n",
    "            print(f\"Force reloading: deleting existing dataset at {self.output_path}\")\n",
    "            os.remove(self.output_path)\n",
    "\n",
    "        # Initialize InMemoryDataset\n",
    "        super().__init__(root=os.path.abspath(graph_dataset_dir))\n",
    "\n",
    "        # Load dataset if it exists\n",
    "        if os.path.exists(self.processed_paths[0]):\n",
    "            self.data, self.slices = load(self.processed_paths[0], weights_only=False)\n",
    "        else:\n",
    "            self.data, self.slices = None, None  # Prevent attribute errors\n",
    "            \n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self): \n",
    "        vasp_files = []\n",
    "        \n",
    "        for root, _, files in os.walk(self.vasp_directory):  \n",
    "            if self.initial_state:  \n",
    "                # Check for \"poscar_1\" and rename if necessary\n",
    "                if \"poscar_1\" in files:  \n",
    "                    poscar_1_path = os.path.join(root, \"poscar_1\")\n",
    "                    poscar_vasp_path = os.path.join(root, \"poscar_1.vasp\")\n",
    "\n",
    "                    if not os.path.exists(poscar_vasp_path):\n",
    "                        shutil.copy(poscar_1_path, poscar_vasp_path)  # Copy instead of rename\n",
    "                        print(f\"Copied {poscar_1_path} -> {poscar_vasp_path}\")\n",
    "\n",
    "                    vasp_files.append(poscar_vasp_path)\n",
    "\n",
    "                # Add POSCAR if it exists\n",
    "                elif \"POSCAR\" in files:  \n",
    "                    vasp_files.append(os.path.join(root, \"POSCAR\"))\n",
    "                \n",
    "                # If augment=True, also add CONTCAR if available\n",
    "                if self.augment and \"CONTCAR\" in files:\n",
    "                    vasp_files.append(os.path.join(root, \"CONTCAR\"))\n",
    "\n",
    "            else:  # Use CONTCAR by default\n",
    "                if \"CONTCAR\" in files:\n",
    "                    vasp_files.append(os.path.join(root, \"CONTCAR\"))\n",
    "\n",
    "                # If augment=True, also check for POSCAR/poscar_1 and rename if necessary\n",
    "                if self.augment:\n",
    "                    if \"poscar_1\" in files:  \n",
    "                        poscar_1_path = os.path.join(root, \"poscar_1\")\n",
    "                        poscar_vasp_path = os.path.join(root, \"poscar_1.vasp\")\n",
    "\n",
    "                        if not os.path.exists(poscar_vasp_path):\n",
    "                            shutil.copy(poscar_1_path, poscar_vasp_path)  # Copy instead of rename\n",
    "                            print(f\"Copied {poscar_1_path} -> {poscar_vasp_path}\")\n",
    "\n",
    "                        vasp_files.append(poscar_vasp_path)\n",
    "\n",
    "                    elif \"POSCAR\" in files:  \n",
    "                        vasp_files.append(os.path.join(root, \"POSCAR\"))\n",
    "\n",
    "        return vasp_files\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self): \n",
    "        return self.output_path\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Process the VASP directory into PyG-compatible graphs using atoms_to_pyg.\n",
    "        Uses multiprocessing to improve speed on large datasets.\n",
    "        \"\"\"\n",
    "        vasp_files = self.raw_file_names\n",
    "\n",
    "        # Preload adsorbate indices to avoid PubChem calls in multiprocessing\n",
    "        print(\"Preloading adsorbate indices...\")\n",
    "        for path in vasp_files:\n",
    "            try:\n",
    "                extract_atom_indices(path)  # fills the cache and avoids HTTP later\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to preload indices for {path}: {e}\")\n",
    "\n",
    "        # Split paths into batches\n",
    "        batch_size = 400  # Adjust based on system memory\n",
    "        data_list = []\n",
    "        \n",
    "        # Process each batch in parallel\n",
    "        def process_batch(batch_paths):\n",
    "            with mp.Pool(self.ncores) as pool:\n",
    "                process_fn = partial(self.atoms_to_data, graph_params=self.graph_params)\n",
    "                return pool.map(process_fn, batch_paths)\n",
    "\n",
    "        for i in range(0, len(vasp_files), batch_size):\n",
    "            print(f\"Processing batch {i} to {i + batch_size} ...\")\n",
    "            batch_paths = vasp_files[i:i + batch_size]\n",
    "            batch_data = process_batch(batch_paths)\n",
    "\n",
    "            # Filter out None and avoid memory sharing issues\n",
    "            batch_data_clean = [deepcopy(d) for d in batch_data if d is not None]\n",
    "            data_list.extend(batch_data_clean)\n",
    "\n",
    "\n",
    "        # Isomorphism test: Removing duplicated data\n",
    "        # print(\"Removing duplicated data ...\")\n",
    "        dataset = []\n",
    "        for graph in data_list:\n",
    "            if graph is not None:\n",
    "                is_duplicate, _ = self.is_duplicate(graph, dataset) \n",
    "                if not is_duplicate:\n",
    "                    dataset.append(graph)\n",
    "        print(f\"Graph dataset size: {len(dataset)}\")\n",
    "\n",
    "        if len(dataset) == 0:\n",
    "            print(\"No valid graphs found. Exiting process function.\")\n",
    "            return\n",
    "\n",
    "        # Collate the data into the format required by PyG\n",
    "        data, slices = self.collate(dataset)\n",
    "\n",
    "        # Save the processed data\n",
    "        save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def is_duplicate(self, \n",
    "                    graph: Data, \n",
    "                    graph_list: list[Data], \n",
    "                    eps: float=0.01) -> tuple:\n",
    "            \"\"\"\n",
    "            Perform isomorphism test for the input graph before including it in the final dataset.\n",
    "            Test based on graph formula and energy difference.\n",
    "\n",
    "            Args:\n",
    "                graph (Data): Input graph.\n",
    "                graph_list (list[Data]): graph list against which the input graph is tested.\n",
    "                eps (float): tolerance value for the energy difference in eV. Default to 0.01 eV.\n",
    "                grwph: data graph as input\n",
    "            Returns:\n",
    "                (bool): Whether the graph passed the isomorphism test.\n",
    "            \"\"\"\n",
    "            \n",
    "            if len(graph_list) == 0:\n",
    "                return False, None\n",
    "            else:\n",
    "                for rival in graph_list:\n",
    "                    if graph.type != rival.type:\n",
    "                        continue\n",
    "                    if graph.num_edges != rival.num_edges:\n",
    "                        continue\n",
    "                    if graph.num_nodes != rival.num_nodes:\n",
    "                        continue\n",
    "                    if graph.formula != rival.formula:\n",
    "                        continue\n",
    "                    if torch.abs(graph.ads_energy - rival.ads_energy) > eps:\n",
    "                        continue\n",
    "                    if graph.facet != rival.facet:\n",
    "                        continue\n",
    "                    if graph.material != rival.material:\n",
    "                        continue\n",
    "                    if graph.state != rival.state:\n",
    "                        continue\n",
    "                    if graph.adsorbate_name != \"None\":\n",
    "                        if graph.adsorbate_name != rival.adsorbate_name:\n",
    "                            continue\n",
    "                    # if graph.bb_type != rival.bb_type: # for TSs\n",
    "                    #     continue\n",
    "                    print(\"Isomorphism detected for {}\".format(graph.formula))\n",
    "                    return True, graph_list.index(rival)\n",
    "                return False, None\n",
    "\n",
    "    def atoms_to_data(self, structure: Union[Atoms, str], \n",
    "                    graph_params: dict[str, Union[float, int, bool]], \n",
    "                    model_elems: list[str] = ADSORBATE_ELEMS + METALS, \n",
    "                    calc_type: str='int', \n",
    "                    adsorbate_elements =ADSORBATE_ELEMS) -> Data:\n",
    "        \"\"\"\n",
    "        Convert ASE objects to PyG graphs for inference.\n",
    "        (target values are not included in the Data object).\n",
    "\n",
    "        Args:\n",
    "            structure (Atoms): ASE atoms object or POSCAR/CONTCAR file.\n",
    "            graph_params (dict): Dictionary containing the information for the graph generation in the format:\n",
    "                                {\"tolerance\": float, \"scaling_factor\": float, \"metal_hops\": int, \"second_order_nn\": bool}\n",
    "            model_elems (list): List of chemical elements that can be processed by the model.\n",
    "            calc_type (str): Type of calculation. \"int\" for intermediates, \"ts\" for transition states.\n",
    "            adsorbate_elements (list): List of adsorbate elements. Default to [\"C\", \"H\", \"O\", \"N\", \"S\"].\n",
    "        Returns:\n",
    "            graph (Data): PyG Data object.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(structure, str):\n",
    "            path = structure  \n",
    "            structure = read(structure)\n",
    "        elif not isinstance(structure, Atoms):\n",
    "            raise TypeError(\"Structure must be of type ASE Atoms or POSCAR/CONTCAR file path.\")\n",
    "        \n",
    "        # Debug statement\n",
    "        if not isinstance(structure, Atoms):\n",
    "            print(\"Structure is not an ASE Atoms object.\")\n",
    "        \n",
    "        # Get list of elements in the structure\n",
    "        elements_list = list(set(structure.get_chemical_symbols()))\n",
    "        if not all(elem in model_elems for elem in elements_list):\n",
    "            raise ValueError(\"Not all chemical elements in the structure can be processed by the model.\")\n",
    "        \n",
    "        # Read graph conversion parameters\n",
    "        graph_structure_params = graph_params[\"structure\"]\n",
    "        graph_features_params = graph_params[\"features\"]\n",
    "        formula = structure.get_chemical_formula()\n",
    "\n",
    "        # Construct one-hot encoder for elements\n",
    "        ohe_elements = OneHotEncoder().fit(np.array(model_elems).reshape(-1, 1)) \n",
    "        elements_list = list(ohe_elements.categories_[0])\n",
    "        node_features_list = list(ohe_elements.categories_[0]) \n",
    "        \n",
    "        adsorbate_indices = extract_atom_indices(path, offline=True)\n",
    "\n",
    "        # append to node_features_list the key features whose value is True, in uppercase\n",
    "        for key, value in graph_features_params.items():\n",
    "            if value:\n",
    "                node_features_list.append(key.upper())\n",
    "        graph, ase_to_graph_idx, _ = atoms_to_pyg(structure, \n",
    "                                            calc_type,\n",
    "                                            graph_structure_params[\"tolerance\"], \n",
    "                                            graph_structure_params[\"scaling_factor\"],\n",
    "                                            graph_structure_params[\"surface_order\"], \n",
    "                                            ohe_elements, \n",
    "                                            adsorbate_indices)  \n",
    "        graph.formula = formula\n",
    "        graph.node_feats = node_features_list\n",
    "        graph.adsorbate_indices = adsorbate_indices # Indices of the atoms object belonging to the adsorbate \n",
    "\n",
    "        metadata = extract_metadata(path)\n",
    "\n",
    "        graph.state = metadata[\"state_of_origin\"]\n",
    "\n",
    "        graph.material = metadata[\"material\"]\n",
    "        graph.adsorbate_group = metadata[\"adsorbate_group\"]\n",
    "        graph.adsorbate_name = metadata[\"adsorbate_name\"]\n",
    "\n",
    "        graph.facet = metadata[\"facet\"]\n",
    "        graph.type = metadata[\"type\"]\n",
    "        # graph.spin_polarization = metadata[\"spin_polarization\"]\n",
    "        \n",
    "        graph.energy = tensor([metadata[\"total_energy\"]]) if metadata[\"total_energy\"] is not None else tensor([0.0])\n",
    "        graph.slab_energy = tensor([metadata[\"slab_energy\"]]) if metadata[\"slab_energy\"] is not None else tensor([0.0])\n",
    "        graph.adsorbate_energy = tensor([metadata[\"adsorbate_energy\"]]) if metadata[\"adsorbate_energy\"] is not None else tensor([0.0])\n",
    "        graph.ads_energy = tensor([metadata[\"adsorption_energy\"]]) if metadata[\"adsorption_energy\"] is not None else tensor([0.0])\n",
    "        graph.target = tensor([metadata[self.target]]) if metadata[self.target] is not None else tensor([0.0])\n",
    "\n",
    "\n",
    "        graph.dissociation = fragment_filter(graph, ase_to_graph_idx)\n",
    "        \n",
    "        # # NODE FEATURIZATION\n",
    "        try:\n",
    "        #     if graph_features_params[\"adsorbate\"]:\n",
    "        #         graph = adsorbate_node_featurizer(graph, adsorbate_elements)\n",
    "        #     if graph_features_params[\"radical\"]:\n",
    "        #         graph = get_radical_atoms(graph, adsorbate_elements)\n",
    "        #     if graph_features_params[\"valence\"]:\n",
    "        #         graph = get_atom_valence(graph, adsorbate_elements)\n",
    "            if graph_features_params[\"cn\"]:\n",
    "                graph = get_cn(graph, structure)\n",
    "        #     if graph_features_params[\"magnetization\"]:\n",
    "        #         graph = get_magnetization(graph)\n",
    "            if graph_features_params[\"ads_height\"]:\n",
    "                graph = get_adsorption_heights_plane_fit(path, graph)\n",
    "            return graph\n",
    "        except:\n",
    "            print(\"Error in node featurization for {}\\n\".format(formula))\n",
    "            return None\n",
    "        \n",
    "        # return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_params = {\"structure\": {\"tolerance\": 0.3, \"scaling_factor\": 1.25, \"surface_order\": 2},\n",
    "                \"features\": {\"adsorbate\": False, \"radical\": False, \"valence\": False, \"cn\": True, \"magnetization\": False, \"ads_height\": False},\n",
    "                \"target\": \"adsorption_energy\"}\n",
    "\n",
    "# 0.25 Å tolerance, 1.25 scaling factor, 3rd NN surface order works for metal oxides\n",
    "# 0.3 Å tolerance needed for the Zn slab\n",
    "\n",
    "# vasp_directory = \"/BACKUP/database_2/surface_adsorbates/Ir\"\n",
    "vasp_directory = \"/BACKUP/database_3/oxide_adsorbates/IrO2/amides/Formamide/metal\"\n",
    "graph_dataset_dir = \"/home/tvanhout/oxides_ML/models/test_graph_datasets\"\n",
    "\n",
    "dataset = OxidesGraphDataset(vasp_directory, graph_dataset_dir, graph_params, initial_state=False, force_reload=True, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.isnan(dataset.x).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.min(dataset.x), torch.max(dataset.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in range(len(dataset)):\n",
    "    if dataset[graph].dissociation == True:\n",
    "        print(dataset[graph].state)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.ohe_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in dataset:\n",
    "    if graph.adsorbate_name == \"Methanol\":\n",
    "        graph_plotter(graph)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0].elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for graph in dataset:\n",
    "#     if graph.type == \"adsorbate\":\n",
    "#         print(graph.idx)\n",
    "\n",
    "print(dataset[-1].idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for graph in dataset:\n",
    "#     if graph.type == \"adsorbate\":\n",
    "#         print(graph.adsorbate_indices)\n",
    "\n",
    "print(dataset[-1].adsorbate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[-1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oxides_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

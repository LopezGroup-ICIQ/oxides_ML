04-Apr-2025, 11:50:10
Device = NVIDIA RTX A2000 12GB
Training time = 2.29 min
---------------------------------------------------------
GRAPH REPRESENTATION PARAMETERS
Voronoi tolerance = 0.25 Angstrom
Atomic radius scaling factor = 1.25
Second order metal neighbours inclusion = True
Node adsorbate/surface descriptor = False
Node radical descriptor = False
---------------------------------------------------------
GNN ARCHITECTURE
Activation function = ReLU
Number of convolutional layers = 3
Number of fully connected layers = 0
Depth of the layers = 128
Bias presence in the layers = False
---------------------------------------------------------
TRAINING PROCESS
Dataset Size = 1069
Data Split (Train/Val/Test) = 60-20-20 %
Target scaling = std
Target (train+val) mean = -1.349840 eV
Target (train+val) standard deviation = 1.005935 eV
Epochs = 250
Batch size = 16
Optimizer = Adam
Learning Rate scheduler = Reduce Loss On Plateau
Initial learning rate = 1e-05
Minimum learning rate = 1e-07
Patience (lr-scheduler) = 5
Factor (lr-scheduler) = 0.7
Loss function = mae
---------------------------------------------------------
GNN PERFORMANCE
Test set size = 213
Mean Bias Error (MBE) = 0.075 eV
Mean Absolute Error (MAE) = 0.670 eV
Root Mean Square Error (RMSE) = 0.797 eV
Error Standard Deviation = 0.794 eV
R2 = 0.375 
Sharpness = 0.816 eV
Coefficient of variation = 0.000 [-]
Miscalibration area = 0.015 [-]
---------------------------------------------------------
OUTLIERS (TEST SET)
